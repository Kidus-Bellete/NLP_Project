{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNN2bR0TXpAoGXJI7EtPul4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kidus-Bellete/NLP_Project1/blob/main/nlp_assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Natural Language Processing Assignment I**\n",
        "#     Classification of Texts using Wikipedia"
      ],
      "metadata": {
        "id": "tM9JIjLn4pj_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6mWM6JBM3EWN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "MCvJPKpx3uYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titles = [\"Medicine\", \"Hospital\", \"Surgery\", \"Health\", \"Heart\", \"Vaccine\",\"endurance\",\"brain\",\"stomach\",\"Therapy\",\n",
        "          \"Pharmacy\", \"Immunology\", \"Pathology\", \"Treatment\", \"Diabetes\", \"Disease\",\n",
        "          \"Therapy\", \"Dentistry\", \"Kidney\", \"Blood\", \"Blood pressure\", \"Virus\",\n",
        "          \"Art\", \"Language\", \"Literature\", \"Philosophy\",\n",
        "          \"Empire\", \"Space\", \"Environment\", \"Color\", \"Mountain\",\"rule of law\",\"justice\",\n",
        "          \"Forest\", \"Cooking\", \"Theology\", \"Fashion\",\"animal\",\"love\",\"tree\",\n",
        "          \"History\", \"Geography\", \"Archaeology\", \"government\", \"Astronomy\"]\n",
        "\n",
        "# Create a data frame\n",
        "df = pd.DataFrame(columns=[\"Text\", \"Label\"])\n",
        "dataArr = []\n",
        "\n",
        "def fetch_data(title):\n",
        "    url = 'https://en.wikipedia.org/w/api.php'\n",
        "    params = {\n",
        "        'action': 'query',\n",
        "        'format': 'json',\n",
        "        'titles': title,\n",
        "        'prop': 'extracts',\n",
        "        'exintro': True,\n",
        "        'explaintext': True,\n",
        "    }\n",
        "    response = requests.get(url, params=params)\n",
        "    data = response.json()\n",
        "    return data\n",
        "\n",
        "# Fetch data and preprocess text\n",
        "for topic in titles:\n",
        "    data = fetch_data(topic)\n",
        "    topic_data = next(iter(data['query']['pages'].values()))\n",
        "    dataArr.append(topic_data['extract'][:500])\n",
        "\n",
        "data = {\"Text\": dataArr, \"Label\": [\"Medical\"] * 22 + [\"Non-Medical\"] * 23}\n",
        "try:\n",
        "    df_added = pd.DataFrame(data)\n",
        "    df = pd.concat([df, df_added], ignore_index=True)\n",
        "    df.to_csv('nlp_dataset.csv', index=False)\n",
        "\n",
        "    # Tokenization, lemmatization, and stemming function\n",
        "    def preprocess_text(text):\n",
        "        # Tokenization\n",
        "        tokens = word_tokenize(text.lower())  # Convert to lowercase for consistency\n",
        "\n",
        "        # Remove stopwords\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        tokens = [token for token in tokens if token.isalnum() and token not in stop_words]\n",
        "\n",
        "        # Lemmatization\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "        # Stemming\n",
        "        stemmer = PorterStemmer()\n",
        "        tokens = [stemmer.stem(token) for token in tokens]\n",
        "\n",
        "        return ' '.join(tokens)\n",
        "\n",
        "    # Apply preprocessing to the entire dataset\n",
        "    df['Text'] = df['Text'].apply(preprocess_text)\n",
        "\n",
        "except ValueError as e:\n",
        "    print(f\"ValueError: {e}\")\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFqkjhMM3Ppf",
        "outputId": "705091dc-096c-40cf-e20c-430c2b9d6108"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                 Text        Label\n",
            "0   medicin scienc practic care patient manag diag...      Medical\n",
            "1   hospit healthcar institut provid patient treat...      Medical\n",
            "2   surgeri medic specialti us manual instrument t...      Medical\n",
            "3   common usag medicin health accord world health...      Medical\n",
            "4   heart muscular organ anim organ pump blood blo...      Medical\n",
            "5   vaccin biolog prepar provid activ acquir immun...      Medical\n",
            "6   endur also relat suffer forbear resili constit...      Medical\n",
            "7   brain encephalon organ serf center nervou syst...      Medical\n",
            "8   stomach muscular hollow organ gastrointestin t...      Medical\n",
            "9   therapi medic treatment attempt remedi health ...      Medical\n",
            "10  pharmaci scienc practic discov produc prepar d...      Medical\n",
            "11  immunolog branch biolog medicin cover studi im...      Medical\n",
            "12  patholog studi diseas injuri word patholog als...      Medical\n",
            "13  treatment may refer treatment song 2012 song l...      Medical\n",
            "14  diabet mellitu often known simpli diabet group...      Medical\n",
            "15  diseas particular abnorm condit advers affect ...      Medical\n",
            "16  therapi medic treatment attempt remedi health ...      Medical\n",
            "17  dentistri also known dental medicin oral medic...      Medical\n",
            "18  human kidney two organ multilobar multipapilla...      Medical\n",
            "19  blood bodi fluid circulatori system human vert...      Medical\n",
            "20  blood pressur bp pressur circul blood wall blo...      Medical\n",
            "21  viru submicroscop infecti agent replic insid l...      Medical\n",
            "22  art divers rang human activ result product inv...  Non-Medical\n",
            "23  languag structur system commun consist grammar...  Non-Medical\n",
            "24  literatur collect written work also use narrow...  Non-Medical\n",
            "25  philosophi love wisdom ancient greek systemat ...  Non-Medical\n",
            "26  empir polit unit made sever territori peopl us...  Non-Medical\n",
            "27  space continuum contain posit direct classic p...  Non-Medical\n",
            "28  environ often refer natur environ live thing o...  Non-Medical\n",
            "29  color american english colour commonwealth eng...  Non-Medical\n",
            "30  mountain elev portion earth crust gener steep ...  Non-Medical\n",
            "31  rule law polit ideal citizen institut within c...  Non-Medical\n",
            "32  justic broadest sens concept individu treat ma...  Non-Medical\n",
            "33  forest area land domin tree hundr definit fore...  Non-Medical\n",
            "34  cook also known cookeri profession culinari ar...  Non-Medical\n",
            "35  theolog systemat studi natur divin broadli rel...  Non-Medical\n",
            "36  fashion term use interchang describ creation c...  Non-Medical\n",
            "37  anim multicellular eukaryot organ biolog kingd...  Non-Medical\n",
            "38  love encompass rang strong posit emot mental s...  Non-Medical\n",
            "39  botani tree perenni plant elong stem trunk usu...  Non-Medical\n",
            "40  histori deriv ancient greek ἱστορία historía k...  Non-Medical\n",
            "41  geographi greek γεωγραφία geographia combin gr...  Non-Medical\n",
            "42  archaeolog archeolog studi human activ recover...  Non-Medical\n",
            "43  govern system group peopl govern organ commun ...  Non-Medical\n",
            "44  astronomi natur scienc studi celesti object ph...  Non-Medical\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "#import pandas as pd\n",
        "\n",
        "# read data\n",
        "df = pd.read_csv('nlp_dataset.csv')\n",
        "print(\"Original data distribution..\")\n",
        "print(df['Label'].value_counts())\n",
        "\n",
        "# training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['Text'], df['Label'], test_size=0.3, random_state=42)\n",
        "\n",
        "# Fill missing values\n",
        "X_train = X_train.fillna('')\n",
        "X_test = X_test.fillna('')\n",
        "\n",
        "# feature extraction\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "# Resampling using SMOTE\n",
        "sampler = SMOTE(sampling_strategy='auto', k_neighbors=5)\n",
        "X_train_resampled, y_train_resampled = sampler.fit_resample(X_train_tfidf, y_train)\n",
        "\n",
        "# Model selection and training\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# model evaluation\n",
        "predictions = model.predict(X_test_tfidf)\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f\"\\nAccuracy: {accuracy}\")\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, predictions))\n",
        "\n",
        "# making predictions\n",
        "# data to predict\n",
        "new_data = [\"head ache is a type of disease \",\n",
        "            \"Ethiopia is the oldest city with many historical heritages.\",\n",
        "            \"He has a chance to recover from his disease\",\n",
        "            \"I love to see Italian historical places.\",\n",
        "            \"Have even been in such kind of discomfort situation? \",\n",
        "            \"How can I feel better and to improve my mood?\",\n",
        "            \"does eating food changes my feeling?\"\n",
        "            #add any sentences to check its prediction value\n",
        "            ]\n",
        "\n",
        "new_data_tfidf = tfidf_vectorizer.transform(new_data)\n",
        "new_predictions = model.predict(new_data_tfidf)\n",
        "\n",
        "print(\"\\nPredictions on new data:\\n\")\n",
        "\n",
        "for text, prediction in zip(new_data, new_predictions):\n",
        "    print(f\"{text} - Predicted: {prediction}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nu0HNaBM4OyW",
        "outputId": "05c59eb6-36ed-4fea-cfee-8ab250bf8c99"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original data distribution..\n",
            "Non-Medical    23\n",
            "Medical        22\n",
            "Name: Label, dtype: int64\n",
            "\n",
            "Accuracy: 0.9285714285714286\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     Medical       1.00      0.83      0.91         6\n",
            " Non-Medical       0.89      1.00      0.94         8\n",
            "\n",
            "    accuracy                           0.93        14\n",
            "   macro avg       0.94      0.92      0.93        14\n",
            "weighted avg       0.94      0.93      0.93        14\n",
            "\n",
            "\n",
            "Predictions on new data:\n",
            "\n",
            "head ache is a type of disease  - Predicted: Medical\n",
            "Ethiopia is the oldest city with many historical heritages. - Predicted: Non-Medical\n",
            "He has a chance to recover from his disease - Predicted: Medical\n",
            "I love to see Italian historical places. - Predicted: Non-Medical\n",
            "Have even been in such kind of discomfort situation?  - Predicted: Non-Medical\n",
            "How can I feel better and to improve my mood? - Predicted: Medical\n",
            "does eating food changes my feeling? - Predicted: Non-Medical\n"
          ]
        }
      ]
    }
  ]
}